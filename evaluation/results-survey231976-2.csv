"id. Response ID","submitdate. Date submitted","startdate. Date started","G1Q00001. Your current study program?","G1Q00001[other]. Your current study program? [Other]","G1Q00002. Bachelor or Master? ","G1Q00003. In which semester were you in SS24?(If you are a master student, only count your master semesters and do not count your bachelor semesters) ","G1Q00004. Which OS (operating system) do you use on your laptop?","G1Q00005. Which internet browser do you usually use?","G1Q00006. How would you describe your programming experience?","G2Q00001. The direct automated feedback from Artemis keeps me more engaged in the learning process.","G2Q00002. The direct automatic feedback from Artemis motivates me to repeatedly improve my code. ","G2Q00003. The direct automated feedback from Artemis makes me feel more motivated to complete my programming assignments. ","G2Q00004. The direct automated feedback from Artemis encourages me to experiment more with my coding solutions.","G3Q00001. I feel more comfortable requesting direct automated feedback from Artemis than feedback from a human tutor.","G3Q00002. I am likely to request feedback more frequently when using direct automated feedback from Artemis than feedback from my course professor.","G3Q00003. I find receiving direct automated feedback from Artemis less intimidating than receiving feedback from a human tutor.","G3Q00004. I feel that requesting direct automated feedback from Artemis is more convenient than arranging a meeting with a human tutor.","G4Q00001. The direct automated feedback provided by Artemis helps me understand my mistakes.","G4Q00002. The direct automated feedback from Artemis is more effective than one-time feedback.","G4Q00003. The direct automated feedback has significantly improved the quality of my programming assignment.","G4Q00004. The direct automated feedback is a helpful addition to the automatic test case results.","G4Q00005. I feel that having access to direct automated feedback from Artemis continously helps me more than arranging a meetings with a human tutor.","G5Q00001. It is easy to receive direct automated feedback from Artemis on my programming assignments.","G5Q00002. I would rather use the direct automated feedback integrated into Artemis than use an external AI tool for getting feedback.","G5Q00003. I find the direct automated feedback from Artemis helpful in improving my programming skills.","G5Q00004. I am satisfied with the overall performance of the direct automated feedback.","G5Q00005. Are there any improvements that you would suggest for direct automated feedback?","G5Q00006. How did you find the feedback?","G5Q00007. What kind of feedback would you like to receive?","G5Q00008. Was there anything you particularly liked about the direct automated feedback process?","G5Q00009. What difficulties did you encounter when using the direct automated feedback process?"
"1","2024-06-10 12:25:13","2024-06-10 12:20:28","Informatics","","Bachelor","6","MacOS","Safari","Advanced","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Agree","Strongly Agree","Agree","Strongly Agree","Neutral","Strongly Agree","Strongly Agree","Agree","Agree","- Some kind of ordering by ""category"" or importance would be nice, currently feedback on leftover TODO comments are in between more important feedback.
- It would be great to see some kind of visual indication as to how far the system is with generating feedback (if possible).
But the general positive feedback like ""You've done well with xyz"" are great!","","","",""
"2","2024-06-10 12:38:12","2024-06-10 12:33:52","Information Systems","","Bachelor","8","MacOS","Opera","Advanced","Neutral","Neutral","Agree","Neutral","Agree","Agree","Agree","Agree","Agree","Agree","Neutral","Agree","Agree","Agree","Disagree","Agree","Disagree","the feedback was not provided in a structured manner. It was difficult to categorize the errors and find the errors in the code to which the feedback was referring to.","","","",""
"3","2024-06-10 12:51:07","2024-06-10 12:41:27","Informatics","","Master","6","MacOS","Arc","Intermediate","Agree","Agree","Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Agree","Neutral","Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","It's hard to distinguish which feedbacks are more relevant to improve the solution at the first glance, as each feedback has the same colour and AI usually generate many feedbacks. 
Doing a sentiment analysis on AI feedbacks and assigning them colours according to the feedback type (like in automatic test results green, yellow or red) can help users better focus on feedbacks that highlight their mistakes or suggestions sent by AI. 

Example:
Good job: Green
Can be improved: Yellow
Missing or not implemented: Red","","","",""
"4","2024-06-10 13:07:20","2024-06-10 13:02:22","Information Systems","","Bachelor","10","MacOS","Arc","Intermediate","Agree","Agree","Agree","Strongly Agree","Neutral","Strongly Agree","Disagree","Strongly Agree","Agree","Agree","Agree","Neutral","Agree","Strongly Agree","Neutral","Agree","Agree","","","","",""
"5","2024-06-13 12:40:06","2024-06-13 12:29:42","Informatics","","Master","3","MacOS","Google Chrome","Expert","Strongly Agree","Agree","Strongly Agree","Neutral","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Agree","Strongly Agree","Strongly Agree","Agree","Agree","Agree","Strongly Agree","Better UX when asking for feedback, so that I can see something is happening. Currently I don't know if it just takes quite some time, or if it already completed and I should refresh my browser. Also the first time, I didn't know where to click to see the Automated Feedback.","Quite relevant, it helped me fix some obvious oversights at the beginning","Mostly about my mistakes, point out where and why it's wrong","The fact that with this tool, I wouldn't have to sit for hours debugging a cryptic hidden test case which I don't even know where to look out for. With this, some small and hidden mistakes that make the tests fail can be found way quicker. Also it applies the context of the exercise to the feedback, which guides me in the right direction.","It is nice that it tells you that you did a good job at something, however currently all feedback (good or bad) is classified the same way. I'm mostly interested in my mistakes, so I think it would make it even better if those would have another background color (or something like this), so that I know at a glance where I should improve my code."
"6","2024-06-17 12:52:43","2024-06-17 12:30:34","Informatics","","Bachelor","6","Linux","Google Chrome","Advanced","Agree","Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Agree","Neutral","Agree","Strongly Agree","Agree","Agree","Neutral","Agree","Neutral","The direct automation seems to review things that I have already done correctly. For me, this is overkill. I would prefer to receive fewer informational messages. For example, I received 15 informational messages, and 5 of them pertained to things I did correctly. It’s hard to go through all 15 messages. Additionally, there are multiple messages about todos. I don’t need feedback for every todo message. Maybe one message that includes all the feedback regarding the todos would be better. I would suggest this for every kind of unclear statement, since when there is a big exercise and a student receives 20-30 feedback messages, it's hard to parse through all of them and can be a bit annoying. So the same kind of feedback could be coupled together.","Feedback seems to cover almost everything. However, when I left out just one getter/setter in the exercise, it didn't recognize this. Another common mistake that students make is getting the order of the parameters in the constructors wrong. It would be nice to receive feedback on the order of the parameters in the constructor when they are incorrect.","Combine feedback messages when they are of the same type. If my code is not compiling, I would like to receive feedback about this. When I had a build fail and wanted direct automated feedback, it didn't recognize the error explaining why my code didn't compile or why the build failed. I think this would be a great addition since new starters tend to have compile errors and don't understand why.","I liked that it mentions the best code practices, which is very useful for maintaining clean code. It also covers design patterns so students can further research them on their own.","Receiving too much feedback can be overwhelming. It would also be nice to have a progress bar or loading screen to indicate that the feedback is being generated, as I did not understand if my request was being processed until I received it. Additionally, some mistakes, such as forgetting a getter/setter or compile errors, were not detected in the feedback."
"7","2024-06-17 12:45:14","2024-06-17 12:37:09","Informatics","","Master","6","Linux","Firefox","Expert","Agree","Agree","Agree","Neutral","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Disagree","Agree","Strongly Agree","Neutral","Strongly Agree","From a UI perspective the (see more) button is a bit useless, probably just displaying all the text straight away would be nicer","Helpful, and also very detailed","To get a better learning experience the AI should probably not provide feedback, which does not yet reveal the correct solution, but nudges the student in the right direction to solve the task by themselves. ","Getting a detailed feedback, not just based on the test cases.","It takes a few minutes to receive the automated feedback"
"8","2024-06-17 13:01:33","2024-06-17 12:43:23","Informatics","","Bachelor","6","MacOS","Google Chrome","Advanced","Agree","Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Agree","Agree","Agree","Agree","Agree","Agree","Strongly Agree","Agree","Agree","I think it would be better to color code the feedback given based on if it is feedback that points out that I've done something well or constructive feedback that suggests changes/improvements or feedback including generally tips that one should keep in mind while programming. This would be helpful to differentiate the feedback and have an overview of what one has done in a ""good"" way and where there is still room for improvement.
Maybe clustering them would also be an option?
I would also suggest adding some kind of header that describes what the feedback is about, instead of just ""Feedback · File src/de/tum/...""","The feedback was precise! The process of requesting feedback is very straight forward and intuitive. Sometimes the feedback was referring to the wrong lines though (one line above or below).","Good coding practices, task related-feedback, tips to improve readability of code.","How easy it is to use. I also like that one receives ""good"" feedback, which encourages the user and points out what he has done well and should continue doing.","When opening the feedback, I think the user receives too much feedback at once. Limiting the amount of feedback or clustering it to make it visually more appealing and enabling the user to have a better overview would be great!"
"9","2024-06-17 13:05:55","2024-06-17 12:47:18","Informatics","","Master","4","MacOS","Safari","Expert","Agree","Agree","Disagree","Strongly Disagree","Strongly Agree","Strongly Agree","Disagree","Strongly Agree","Agree","Strongly Agree","Disagree","Agree","Agree","Strongly Agree","Agree","Neutral","Strongly Agree","- The button for automatic feedback is visible and not disabled although it is not yet possible to request feedback, e.g when I just started the exercise. Instead only an error message is shown when clicking on it. The button should be at least greyed out.
- Tell the student an approximate amount of time that they should expect. Otherwise the locking of the repository might feel not worth it.
- When reviewing the ai feedback, the feedback boxes barely do not fit all feedback in them and they need to be expanded. But they are already so big and full of text that a quick overview over all feedback is not possible
- Is it possible to request feedback while the latest submission is still building? I wasn't able to verify this to 100% during the three requests
- it is possible to request feedback multiple times without submitting again, wasting the limited amount of requests without any benefit
- If the feedback does not want to improve anything but rather tells me I did something good, it should be green and not blue
- Show the maximum amount of requests
- Watch out with using green for the feedback text and the checkmark as icon, since they normally mean that the student successfully solved the exercise","- Some feedback was about parts that I did not change yet. The ai should detect which tasks I tried to solve
- Some feedbacks felt a bit redundant or addressed really similar stuff","- Feedback about code style is good, as long as the student already is on a good way to solve the task. Otherwise it could distract or confuse the student. It shouldn't be feedback, that tools like pmd, spotbugs, ... provide
- Feedback that helps solving the current task, but only if the student seems to be stuck. Students should also learn to look for errors themselves","It worked well overall, but there wasn't anything that stuck out to me.","I did not encounter any actual difficulties, see feedback for a few smaller nitpicks and suggestions"
"10","2024-06-17 13:17:17","2024-06-17 12:52:10","Informatics","","Master","3","MacOS","Google Chrome","Advanced","Agree","Disagree","Strongly Agree","Agree","Agree","Strongly Agree","Agree","Strongly Agree","Agree","Strongly Agree","Agree","Agree","Agree","Strongly Agree","Agree","Agree","Agree","I think that the UserExperience can be improved. E.g., I tried what happens if I request feedback without a submission, which resulted in an alert ""You have to submit your work at least once."" - I think the button should be disabled and greyed out, and the alert text in the tooltip description of the button if there was no submission yet.

","It gives good starting points if you are stuck on an exercise to know how and where to continue - this is how I would use the feature in practice.

It would be important that there is a low rate of suggestions that are not relevant. Otherwise, I would probably stop using the feature and start asking GitHub Copilot for suggestions.
(In my case I got the feedback to re-order the variables, even though, as far as I can see I did already have them in the suggested order: ""It's great to see that you've kept the class members organized by their access modifiers. However, it seems that the 'semester' and 'email' fields have been moved in the class body. While this change does not affect the functionality, it's important to maintain a consistent order of fields for readability. Typically, fields are grouped together, and it's common to place all final fields before mutable ones."")","Especially feedback regarding where I can improve. I would prefer getting directly to that information instead of getting told what has been good about the previous submission (e.g. ""You've done well to identify that the `Student` class needs refactoring as per the TODO comments. As you progress, consider how you can apply the template method design pattern to eliminate any duplication between the `Student` and `Professor` classes. This will involve identifying common behaviors and structuring your classes to allow for shared code while preserving the unique aspects of each class."" - here, I would not need the first sentence)","I think the constant and barrier-free availability (no scheduling of appointments / arrangement of working times) fits the students everyday life well!","When I requested the feedback for the first time, I did not see a loading indicator, which confused me.

I also think that more inexperienced users will not know where to find the feedback, that they will have to click on the text of the new item in the timeline. It is only intuitive for users who have already worked on programming exercises and know that they can see test results there.

The state of the feedback process is displayed in text, I think a loading Icon would be more beneficial and easier for the user than reading text that says that the result is still building."
"11","2024-06-17 13:37:25","2024-06-17 13:20:37","Informatics","","Master","4","MacOS","Arc","Expert","Neutral","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Neutral","Strongly Agree","Neutral","Agree","Strongly Agree","Disagree","Agree","1. In the repository/editor view on Artemis you should see a marker next to the files that have feedback
2. A hint that the feedback is viewable in the repo/edit view
3. Make the generation faster :D 
4. Maybe don't lock the repo in the time
5. The request button is somewhat hidden next to the other buttons, maybe make it a little more visible?","Solid","Feedback that encourages me to think of ways to improve my code","Requesting it is pretty simple","1. In the repository/editor view the build result sometimes took preference over the AI feedback and the latter was therefore not displayed
2. The feedback could contain overlapping comments, which were not rendered properly in the repository/editor view. See this screencast: https://youtu.be/Js68kq7AvQw"
"12","2024-06-17 13:43:39","2024-06-17 13:31:52","Information Systems","","Master","2","MacOS","Safari","Intermediate","Agree","Strongly Agree","Neutral","Agree","Neutral","Agree","Neutral","Agree","Agree","Strongly Agree","Agree","Strongly Agree","Neutral","Strongly Agree","Neutral","Neutral","Agree","I think now especially that my only task was to wait for the feedback, it felt a bit slow for the first feedback. But the ones thereafter came back a lot quicker. Also, it gives further improvement suggestions (e.g. writing Javadoc or coding conventions) which definitely is good practice but not directly asked from the practice instructions. Maybe these general improvement instructions can be highlighted differently (as general feedback).","I think the feedback was worded very well overall and motivated to do more and also implement the feedback into the code with its encouraging texts. So in general I think it is very good feedback when you need some intermediary feedback when doing a task but it should not substitute a human tutor giving a final feedback. But for it's purpose I think it's very good.","I think the feedback as currently received fits my needs quite well.","The language used was very encouraging and I also think that the tips in general were quite useful. Also, in itself, it's a good option to get feedback when you're just working on your exercises at home (or elsewhere) and cannot ask tutors/colleagues, etc.","No real difficulties, but I guess the feedback is a bit overwhelmingly much and so it could be structured/coloured better to make it clearer."
"13","2024-06-17 13:44:06","2024-06-17 13:37:46","Information Systems","","Master","4","MacOS","Safari","Expert","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Group information from the feedback per class. Highlight errors, warnings and positive feedback in respective colors.","Helpful, I learned something about attribute arrangements.","Implementation specific but also best practices.","Easy to request and read through the feedback as it was concise.","Keep the overview because it was not grouped per class."
"14","2024-06-17 13:56:09","2024-06-17 13:46:00","Informatics","","Master","4","MacOS","Safari","Expert","Strongly Agree","Strongly Agree","Strongly Agree","Disagree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Agree","Agree","Neutral","Agree","Disagree","Strongly Agree","Agree","Strongly Agree","Agree","I like the detail and helpfulness of the current feedback","While the AI tools used in Artemis are tailored to promote a student`s learning experience, most students are probably focussed on getting the exercise done asap. The current automated feedback shows a lot of positive (""You've done a great job! .."") feedback instead of shutting up (like the automated tests which quietly pass). This makes it hard to distinguish important recommendations from useless reading time.","I like the detail and helpfulness of the current feedback","It´s very easy to access, the boundaries are super-low :)","I did not like to wait for both the submission and the AI feedback to process - maybe you can increase the LLMs speed or pre-load it in some way?"
"15","2024-06-17 13:56:19","2024-06-17 13:50:32","Informatics","","Bachelor","6","MacOS","Firefox","Advanced","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Neutral","Strongly Agree","Strongly Agree","in certain instances I found the AI a bit overcorrective in its feedback. For example feedback it gave for toString methods in my implementation seemed unnecessary. But this is something you can easily tweak, the overall concept is mind-blowing","Very useful. I referred to it and this made me work faster. ","It would be great if you could pick the level of the feedback - for example: ""show me only the big errors"" or ""show me medium errors and above or ""show me everything"" - this would be very useful in the work process","I found the answers pretty good and liked the process overall.","I didn't encounter any problem per se, but I think the cost of 2000+ people (e.g for pgdp) requesting feedbacks over and over again in the semester will not be cheap for you guys."
"16","2024-06-17 14:57:22","2024-06-17 14:38:36","Informatics","","Master","2","MacOS","Safari","Advanced","Strongly Agree","Neutral","Neutral","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Neutral","Strongly Agree","Disagree","Strongly Agree","Agree","Strongly Agree","Neutral","Neutral","Neutral","Possibly give the ai feedback (items ?) a heading, expand them by default, and use a more neutral color.
The AI feedback looks a lot like the list of failed tests.","The feedback was mostly irrelevant. Only a few feedbacks could help me solve the assignment.","- Feedback based on what tests still fail.
- Feedback on how I could potentially improve my own solutions.
- Possibly feedback on what I have done well.","The AI feedback took changes from the last commit into account :)","When I first saw the popup, I had to read it carefully. That's because I first thought that the repository would be locked permanently after requesting feedback. This didn't seem right and I read the popup more carefully.
I also cannot remember if the remaining amount of ai feedback was communicated through the UI. "
"17","2024-06-17 14:58:43","2024-06-17 14:39:30","Informatics","","Bachelor","6","MacOS","Safari","Advanced","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","It would be nice if there was some kind of information where/who is handling the data to give your feedback. E.g. if it's handled by an external model or with an on premise model within TUM. ","It's very nice that it gives individual feedback to the sections of code that were changed in the last commit. The feedback adapts to the ""status"" of your code. If there are still big parts of the implementation missing, it will review it in a broader way. Once you continue coding, it gets more granular. ","It would also be nice to include CodeStyle and clean Code comments in there, e.g. if the variable names and the general flow of code is understandable for other developers. This would really benefit courses that don't have group projects. ","Imo this would also be huge improvement for Artemis coming from the student perspective (the feedback Artemis gives with static tests is usually quite useless, and the lecturer has to spend a lot of time to write it), but would also save tutors & lecturers a lot of work explaining/solving ""minor"" coding errors. 
The big advantage is that the ""Direct Automated Feedback""  has knowledge of the problem statement AND the code, which makes it easier to use than e.g. Github Copilot (no knowledge of problem statement), and ChatGPT (manual copying of code and problem statement necessary). ","Generating the Feedback takes quite long, but I think that depends on the model and its ressources. 
What makes it a bit confusing is that it says ""this repository will be locked while the feedback is generated"", maybe it would be useful if the feedback was linked to a commit. Then a small disclaimer, ""new commits won't affect this feedback until it's fully generated"" would be enough. Otherwise it could cause people to be ""scared"" of using the feature. "
"18","2024-06-17 14:54:04","2024-06-17 14:45:37","Informatics","","Master","3","MacOS","Other","Intermediate","Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","","I find the feedback detailed and useful. Even for this small exercise, there were a lot of things that I overlooked that I have realized through the feedback.","","I didn't expect it to be this detailed. It gives feedback on nearly every line of code and I think it would be especially useful for beginners","I wasn't sure where the feedback would show up after I requested it for the first time. Maybe some directives on that would be useful."
"19","2024-06-17 14:59:31","2024-06-17 14:47:29","Informatics","","Bachelor","5","MacOS","Safari","Advanced","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Neutral","Strongly Agree","Agree","Strongly Agree","Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Strongly Agree","Group feedback in a visual way (e.g. by classes, packages, etc.), so some visual separator, that way it would be easier to understand which feedback belongs where.","Feedback was helpful, but some feedback was very similar/duplicated while separated by multiple other feedback blocks","Mostly semantical (the IDE already does a lot of syntactical feedback)","It's really informative","Takes quite some time."
"20","2024-06-17 17:40:55","2024-06-17 17:33:10","Informatics: Games Engineering","","Bachelor","6","MacOS","Arc","Advanced","Agree","Agree","Agree","Neutral","Strongly Agree","Strongly Agree","Agree","Strongly Agree","Neutral","Agree","Agree","Agree","Strongly Agree","Agree","Agree","Neutral","Disagree","- colorizing the responses: e.g responses that just say your code is code vs responses that point out actual problems vs. formatting can be improved
- lock mechanism is kind of weird + lock pop up only once would suffies
- responses per section appended to each part would be better","- not so much formatting feedback: e.g feedback for if there are blank lines, even IntelliJ standard formatting does not fulfil AI constraints
- partly wrong feedback: e.g superclass should be a protected class -> does not even compile","primarly what can be better or is not correct and less whats already good in my code","relatively intuitive and fast","none except the responses could be better"

